

<!DOCTYPE html>
<html> 
<head> 
  <meta name="viewport" content="width=device-width, initial-scale=1">
	<meta content="en-us" http-equiv="Content-Language">
	<meta content="text/html; charset=UTF-8" http-equiv="Content-Type">
  <meta name="description" content="Web site for Wei Fu, CS, North Carolina State University">
  <meta name="author" content="Wei Fu">
  <meta name="keywords" content="university, research,software engineering, differential evolution, parameter tuning, open science, optimization, data mining, defect prediction">
	<title>Wei Fu NC State</title> 
</head> 

<!DOCTYPE html>
<html>

<head>
  <title>Wei Fu NC State</title>
  <meta name="viewport" content="width=device-width, initial-scale=1">
  <link rel="stylesheet" href="portfolio.css">
  <link rel="shortcut icon" href="stanford.ico" type="image/x-icon">
</head>

<body>
<div class="container">
  <div class="row">
    <div id="profile-img" class="col-prof-pic cropcircle"></div>
    <div class="col-bio">
      <p align="center" lang="zh-cn"><name>Wei Fu 付 伟</name></p>

      <p>I am currently a machine learning engineer at <a href="http://www.landing.ai">Landing.ai</a>. I was a <a href="https://www.nsf.gov/awardsearch/showAward?AWD_ID=1302216">NSF funded</a> PhD student of <a href="http://www.csc.ncsu.edu">Computer Science</a> at <a href="http://www.ncsu.edu">North Carolina State University</a> under the direction of <a href="http://menzies.us">Dr. Tim Menzies</a>.
      </p>
      
      <p>Before coming to NC State, I was a visiting student of <a href="http://www.tsinghua.edu.cn/publish/auen/index.html">Automation Department </a> at <a href="http://www.tsinghua.edu.cn/publish/newthuen/index.html"> Tshinghua University</a> from Mar. 2012 to May. 2013, where I worked with <a href="http://www.tsinghua.edu.cn/publish/auen/1713/2011/20110520164624642817281/20110520164624642817281_.html"> Dr. Feifei Gao</a>, mainly focusing on signal processing in wireless communication networks. I earned my M.S. in Electrical Engineering from <a href="http://www.bupt.edu.cn"> Beijing University of Posts and Telecommunications</a>, China, in Mar. 2012 and  B.S. in Electrical Engineering from <a href="http://www.njtech.edu.cn">Nanjing Tech University</a>, China, in Jun. 2009.  I was an intern at Software Engineering group of <a href="http://new.abb.com/about/technology/corporate-research-centers/corporate-research-center-united-states">ABB Corporate Research Center US</a> in 2016 summer.</p>

<!--       <div class="row">
        <strong><font color="red"><p>I'm on the job market, looking for industrial and academic positions.</p></font></strong>
      </div> -->


      <p align=center>
        <a href="mailto:wfu@ncsu.edu">Email</a>
        &nbsp;/&nbsp;
        <a href="pdf/WeiFu.pdf">CV</a> &nbsp;/&nbsp;
        <a href="https://scholar.google.com/citations?user=FjMYZqsAAAAJ&hl=en">Google Scholar</a>&nbsp;/&nbsp;
        <a href="https://www.linkedin.com/in/weifoo/">LinkedIn</a>&nbsp;/&nbsp;
        <a href="https://www.github.com/weifoo/">Github</a>
      </p>
    </div>
  </div>
  
<!--   <div class="row">
  	<heading>News</heading>

  </div> -->
  
  <div class="row">
    <heading>Research</heading>
    <p> My research topics mainly focus on how to apply next generation of AI techniques to help improve software quality and aid software process. Techniques that I'm interested in (but not limited to) are transfer learning,  deep learning and search-based optimization. My research question is always: can we do "it" better and faster? 
    </p>
  </div>

  <div class="row">
    <subheading>Preprints</subheading>
  </div>

  <div class="row">
    <div class="col-proj-pic"><img src="img/epsilon.png" ></div>
    <div class="col-proj-desc">
      <a href="https://arxiv.org/pdf/1803.04608.pdf">
        <papertitle> Building Better Quality Predictors Using "ε-Dominance"</papertitle>
      </a><br>
      <strong>Wei Fu</strong>, <a href="http://menzies.us">Tim Menzies</a>, <a href="http://dichen.me">Di Chen</a>, <a href="http://amritag.wixsite.com/amrit">Amritanshu Agrawal</a><br>
      arXiv Preprint, 2018 <br>
      <p>This paper explores DART,  an algorithm especially selected to succeed for large ε software quality prediction problems. DART is remarkable simple yet, on experimentation, it dramatically out-performs three sets of state-of-the-art defect prediction methods. </p>
    </div>
  </div>


    <div class="row">
    <div class="col-proj-pic"><img src="img/gridsearch2017.png" ></div>
    <div class="col-proj-desc">
      <a href="https://arxiv.org/pdf/1609.02613.pdf">
        <papertitle>Why is Differential Evolution Better than Grid Search for Tuning Defect Predictors?</papertitle>
      </a><br>
      <strong>Wei Fu</strong>, <a href="http://menzies.us">Tim Menzies</a>, <a href="http://vivekaxl.com">Vivek Nair</a><br>
      arXiv Preprint, 2017 <br>
      <p> Grid search has been widely used as a parameter tuning method in software engineering community. However, by taking defect prediction task as a case study, we find that differential evolution as a parameter tuner performs if not better, at least as good as grid search but it runs 210X faster.</p>
    </div>
  </div>

  <div class="row">
    <subheading>Journal</subheading>
  </div>

  <div class="row">
  <div class="col-proj-pic"><img src="img/LDA2017.png" ></div>
    <div class="col-proj-desc">
      <a href="https://arxiv.org/pdf/1608.08176.pdf">
        <papertitle>What is Wrong with Topic Modeling?(and How to Fix it Using Search-based Software Engineering)</papertitle>
      </a><br>
      <a href="http://amritag.wixsite.com/amrit">Amritanshu Agrawal</a>, <strong>Wei Fu</strong>, <a href="http://menzies.us">Tim Menzies</a>
      <br> Information and Software Technology (<strong>IST</strong>), 2018(accepted) <br>
      <p> LDA suffers from “order effects”. Applying differential evolution algorithm to tune LDA parameters will dramatically reduce clustering instability and  it also leads to improved performances for supervised as well as unsupervised learning.</p>
    </div>
  </div>

  
  <div class="row">
      <div class="col-proj-pic"><img src="img/HDP2017.png"></div>
      <div class="col-proj-desc">
        <a href="pdf/TSE17.pdf">
          <papertitle>Heterogeneous Defect Prediction</papertitle>
        </a><br>
        <a href="http://lifove.github.io/">Jaechang Nam</a>, <strong>Wei Fu</strong>, <a href="https://www.cse.ust.hk/~hunkim/">Sung Kim</a>, <a href="http://menzies.us">Tim Menzies</a>, <a href="https://ece.uwaterloo.ca/~lintan/">Lin Tan</a><br>
        Transactions on Software Engineering(<strong>TSE</strong>), IEEE, 2017 (accepted). <br>
        <p>Our HDP approach conducts metric selection and metric matching to build a prediction model between projects with heterogeneous metric sets. Our empirical study on 28 subjects shows that about 68% of predictions using our approach outperform or are comparable to WPDP with statistical significance.</p>
      </div>
  </div>
  <div class="row">
    <div class="col-proj-pic"><img src="img/tuning2016.png", width="280"></div>
    <div class="col-proj-desc">
      <a href="https://arxiv.org/pdf/1609.01759.pdf">
        <papertitle>Tuning for Software Analytics: is it Really Necessary?</papertitle>
      </a><br>
      <strong>Wei Fu</strong>, <a href="http://menzies.us">Tim Menzies</a>, <a href="https://people.engr.ncsu.edu/xshen5/">Xipeng Shen</a><br> 
      Information and Software Technology (<strong>IST</strong>) 76 (2016): 135-146.<br>
      <p>We applied differential evolution algorithm  to explore the hyper-parameter space  to learn the best optimal parameters for defect prediction, which improves learners' performance in most cases and terminates quickly.  </p>
    </div>
  </div>



  <div class="row">
    <subheading>Conference</subheading>
  </div>



    <div class="row">
      <div class="col-proj-pic"><img src="img/CK.png" ></div>
      <div class="col-proj-desc">
        <a href="https://arxiv.org/pdf/1803.05067.pdf">
          <papertitle>Applications of Psychological Science for Actionable Analytics</papertitle>
        </a><br>
         <a href="http://dichen.me">Di Chen</a>, <strong>Wei Fu</strong>, <a href="http://rkrsn.us">Rahul Krishna</a>, <a href="http://menzies.us">Tim Menzies</a><br>
        <strong>FSE'18</strong> <br>
        <p> Actionable analytics are those that humans can understand, and operationalize. What kind of data mining models generate such actionable analytics? According to psychological scientists, humans understand models that most match their own internal models, which they characterize as lists of “heuristic” (i.e., lists of very succinct rules). This paper assessed Fast-and-Frugal
        Tree for software analytics.</p>
      </div>
    </div>


    <div class="row">
    <div class="col-proj-pic"><img src="img/500faster2018.png" ></div>
    <div class="col-proj-desc">
      <a href="https://arxiv.org/pdf/1802.05319.pdf">
        <papertitle>500+ Times Faster Than Deep Learning</papertitle>
      </a><br>
      <a>Suvodeep Majumder</a>, <a>Nikhila Balaji</a>, <a>Katie Brey</a>, <strong>Wei Fu</strong>, <a href="http://menzies.us">Tim Menzies</a><br>
      <strong>MSR'18</strong> <br>
      <p> Deep learning methods are useful for high-dimensional data and are becoming widely used in many areas of so ware engineering. Deep learners utilizes extensive computational power and can take a long time to train– making it di cult to widely validate and repeat and improve their results. In this study, we apply local learning on the data sets. Such method is over 500 times faster than deep learning but has similar or better results.</p>
    </div>
  </div>
  
  <div class="row">
    <div class="col-proj-pic"><img src="img/data2018.png" ></div>
    <div class="col-proj-desc">
      <a href="https://arxiv.org/pdf/1801.10241.pdf">
        <papertitle>Data-Driven Search-based Software Engineering</papertitle>
      </a><br>
      <a href="http://vivekaxl.com">Vivek Nair</a>, <a href="http://amritag.wixsite.com/amrit">Amritanshu Agrawal</a>, <a href="http://jianfeng.us">Jianfeng Chen</a>, <strong>Wei Fu</strong>, <a href="http://bigfatnoob.us">George Mathew</a>,<a href="http://menzies.us">Tim Menzies</a>, <a href="http://www.cs.le.ac.uk/people/llm11/">Leandro Minku</a>, <a href="https://cs.adelaide.edu.au/users/markus/">Markus Wagner</a>, <a href="http://azhe825.github.io">Zhe Yu</a><br>
      <strong>MSR'18</strong><br>
      <p> This paper introduces Data-Driven Search-based Software Engineering (DSE), which combines insights from Mining Software Repositories (MSR) and Search-based Software Engineering (SBSE). This paper aims to answer the following three questions: (1) What are the various topics addressed by DSE? (2) What types of data are used by the researchers in this area? (3) What research approaches do researchers use? The paper brie y sets out to act as a practical guide to develop new DSE techniques and also to serve as a teaching resource.</p>
    </div>
  </div>

  <div class="row">
    <div class="col-proj-pic"><img src="img/FSE2017_defect.png" ></div>
      <div class="col-proj-desc">
        <a href="https://arxiv.org/pdf/1703.00132.pdf">
          <papertitle>Revisiting Unsupervised Learning for Defect Prediction</papertitle>
        </a><br>
        <strong>Wei Fu</strong>, <a href="http://menzies.us">Tim Menzies</a><br>
<!--         Proceedings of the European Software Engineering Conference and the ACM SIGSOFT Symposium on the Foundations of Software Engineering (<strong>ESEC/FSE</strong>), 2017.<br> -->
        <strong>FSE'17</strong> <a href="http://fuwei.us/pdf/FSE17_Unsup.pdf">Slides</a><br>
        <p> This paper repeats and refutes Yang et al's FSE'16 paper (1) There
  is much variability in the efficacy of the Yang et al. models, some supervised data is required to
  prune weaker models. (2) When we repeat their analysis on a project-by-project
  basis, supervised methods are seen to work better.</p>
      </div>
    </div>

  <div class="row">
  <div class="col-proj-pic"><img src="img/FSE2017_DL.png" ></div>
    <div class="col-proj-desc">
      <a href="https://arxiv.org/pdf/1703.00133.pdf">
        <papertitle>Easy over Hard: A Case Study on Deep Learning</papertitle>
      </a><br>
      <strong>Wei Fu</strong>, <a href="http://menzies.us">Tim Menzies</a><br>
<!--       Proceedings of the European Software Engineering Conference and the ACM SIGSOFT Symposium on the Foundations of Software Engineering (<strong>ESEC/FSE</strong>), 2017.<br> -->
      <strong>FSE'17</strong>  <a href="http://fuwei.us/pdf/FSE17_EasythanDL.pdf">Slides</a><br>
      <p>  SVM with a simple differential evolution-based parameter tuning can get better performance than deep learning(CNN) method for knowledge units relateness classification task on Stack Overflow. At the same, it is 84X faster than the deep learning method.  </p>
    </div>
  </div>


  <div class="row">
    <div class="col-proj-pic"><img src="img/bellwether.png" ></div>
    <div class="col-proj-desc">
      <a href="pdf/krishnaASE16.pdf">
        <papertitle>Too Much Automation? The Bellwether Effect and Its Implications for Transfer Learning</papertitle>
      </a><br>
      <a href="http://rkrsn.us">Rahul Krishna</a>, <a href="http://menzies.us">Tim Menzies</a>, <strong>Wei Fu</strong><br>
<!--       Proceedings of the 31st IEEE/ACM International Conference on Automated Software Engineering(<strong>ASE</strong>). ACM, 2016.<br> -->
      <strong>ASE'16</strong>
      <p> We find a "bellwether" effect in software analytics. Given N data sets, we find which one produces the best predictions on all the others. This "bellwether" data set is then used for all subsequent predictions.</p>
    </div>
  </div>


    

  
  <div class="row">
    <heading>Teaching</heading>
  </div>

  <div class="row">
    <div class="col-proj-pic"><img src="img/teaching.jpg"></div>
        <br>
        <papertitle>ECE220 Foundations of Electrical & Computer Engineering(Lab)</papertitle><br>
        <br>
        <papertitle>ECE212 Fundamentals of Logic Design(Lab)</papertitle><br>
        <br>
        <papertitle>ECE109 Introduction to Computer Systems(Lab)</papertitle><br>
      <br>
  </div>

<!--   <div class="row">
   <heading>Activities</heading>
  </div>

  <div class="row">
    <subheading>Program Committee</subheading>
    <li>Frontiers in AI and Software Engineering[FAISE'18]</li>
  </div>

  <div class="row">
    <subheading> Reviewer</subheading>
    <li>IST</li>
    <li>ESEM'18(sub)</li>
  </div>

  <div class="row">
    <subheading> Membership</subheading>
    <li>ACM</li>
    <li>IEEE</li>
  </div> -->


  


  


<!--   <div class="row">
    <heading>Selected Coursework</heading>
    <input type='checkbox' style='display: none' id=st>
    <label for=st></label>

    <div class="reveal">
      <ul>
        <li>CS 224N - Natural Language Processing with Deep Learning</li>
        <li>CS 238 - Decision Making Under Uncertainty</li>
        <li>CS 157 - Logic and Automated Reasoning</li>
        <li>CS 273B - Deep Learning in Genomics and Biomedicine</li>
        <li>CS 224U - Natural Language Understanding</li>
        <li>CS 231A - Comp. Vision: 3D Reconstruction to Recognition</li>
        <li>CS 231N - Conv. Neural Networks for Visual Recognition</li>
        <li>CS 246 - Mining Massive Data Sets</li>
        <li>CS 243 - Program Analysis and Optimizations</li>
        <li>CS 149 - Parallel Computing</li>
      </ul>
    </div>
  </div> -->
<hr noshade> 
<!-- <div class="col-proj-pic"><img src="img/nsf_logo.gif"></div> -->
<div class="row">
	  <div class="col-proj-desc">
	    <font size="2">
	      <a href="http://people.eecs.berkeley.edu/~barron/">I like this website! </a>
	      Last updated: 07/01/2018
	    </font>
	  </div>
</div>

<script>
  (function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
  (i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
  m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
  })(window,document,'script','https://www.google-analytics.com/analytics.js','ga');

  ga('create', 'UA-100476396-1', 'auto');
  ga('send', 'pageview');

</script>
</body>
</html>
